{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-065699079970>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def show_image_grids(train_images, train_labels):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[train_labels[i]])\n",
    "    plt.show()\n",
    "\n",
    "#問題一\n",
    "def question1(history):\n",
    "    print(history.history.keys())\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "#問題3\n",
    "def question3():\n",
    "    fashion_mnist = keras.datasets.fashion_mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    print(train_labels)\n",
    "    # one-hot\n",
    "    train_labels = to_categorical(y=train_labels, num_classes=10)\n",
    "    test_labels = to_categorical(y=test_labels, num_classes=10)\n",
    "    print(train_labels)\n",
    "    model = keras.Sequential([keras.layers.Flatten(input_shape=(28,28)),\n",
    "                            keras.layers.Dense(128, bias_initializer='ones', activation=tf.nn.relu),\n",
    "                             keras.layers.Dense(10, bias_initializer='ones', activation=tf.nn.softmax)])\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy']) \n",
    "    \n",
    "    model.fit(train_images, train_labels, epochs=20, callbacks = [cp_callback, tb_callback])\n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "    print(\"test_acc:\",test_acc)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fashion_mnist = keras.datasets.fashion_mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "    print(train_images.shape)\n",
    "    print(train_labels.shape)\n",
    "    print(test_images.shape)\n",
    "    print(test_labels.shape)  \n",
    "\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "    #show_image_grids(train_images, train_labels) \n",
    "    show_image_grids(train_images, train_labels)\n",
    "\n",
    "    # Steps 3~8 \n",
    "    print(\"Step3~8\")\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "\n",
    "\n",
    "    model = keras.Sequential([keras.layers.Flatten(input_shape=(28,28)),\n",
    "                            keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                            keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    tb_callback     = TensorBoard(log_dir='log_fashion')\n",
    "    checkpoint_path = \"ckpt_fashion/cp-{epoch:04d}.ckpt\"\n",
    "    cp_callback     = ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1, period=5)\n",
    "\n",
    "    # Steps 9, 10\n",
    "    print(\"Step9、10\")\n",
    "    history = model.fit(train_images, train_labels, epochs=20, callbacks = [cp_callback, tb_callback])\n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "    print(\"test_acc:\",test_acc)\n",
    "\n",
    "    #問題1\n",
    "    #question1(history)\n",
    "\n",
    "    # Step 12\n",
    "    print(\"Step12\")\n",
    "    num = [\"05\",\"10\",\"15\",\"20\"]  \n",
    "    for i in range(4):\n",
    "        weight_path = \"ckpt_fashion/cp-00\"+num[i]+\".ckpt\"  \n",
    "        model.load_weights(weight_path)\n",
    "        loss, acc = model.evaluate(test_images, test_labels)\n",
    "        print(\"cp-00\"+num[i]+\"_acc:\",acc)\n",
    "  \n",
    "\n",
    "    # Step 13\n",
    "    print(\"Step13\")\n",
    "    prob = model.predict(test_images)\n",
    "    print(prob.shape)\n",
    "    predictions   = np.zeros(shape=(prob.shape[0],1))\n",
    "    test_accuracy = np.zeros(shape=(prob.shape[0],1))\n",
    "    for i in range(prob.shape[0]):      \n",
    "        predictions[i] = np.argmax(prob[i,:])\n",
    "        if predictions[i] == test_labels[i]:\n",
    "            test_accuracy[i] = 1\n",
    "        else:\n",
    "            pass\n",
    "    print(\"test_accuracy:\",np.mean(test_accuracy))\n",
    "\n",
    "    # Step 14\n",
    "    print(\"Step14\")\n",
    "    img = np.zeros((2,28,28))\n",
    "    img[0] = test_images[4]\n",
    "    img[1] = np.fliplr(test_images[4])\n",
    "    prob = model.predict(img)\n",
    "    pred = np.array([0,0]) \n",
    "\n",
    "    for i in range(2):\n",
    "        pred[i] = np.argmax(prob[i,:])\n",
    "        plt.grid(False)\n",
    "        plt.subplot(1,2,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(img[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[pred[i]]+'{:.0%}'.format(prob[i,pred[i]])+\"\\n(shirt is the true label)\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. How many training epochs in model.fit() are required such that the training loss is converged? (epochs=20 其實還未收斂，需畫出 loss vs. epochs 曲線) \n",
    "# 500次epochs測試，在epochs=169時acc第一次達到0.99，在epochs=195之後acc都在0.99以上，約epochs=300之後acc都在0.995左右"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Adjust the batch_size in model.fit(). What will happen if we change batch_size from 32 to 128? (訓練時間是增加或減少？測試正確率是上升或下降？原因為何？)\n",
    "# batch_size=32訓練時間短正確率下降，batch_size=128訓練時間長正確率上升，神經元多訓練時間較長但是較精準。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. What is the difference between the following two options in model.compile()? \n",
    "#\tloss='categorical_crossentropy'\n",
    "#\tloss='sparse_categorical_crossentropy'\n",
    "# categorical_crossentropy的labels要用 One-Hot-Encoding，實作如question3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
